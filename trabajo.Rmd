---
title: "Trabajo"
author: "Héctor García Hernández y David Andreu Roqueta"
date: "2023-10-08"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerias utilizadas

```{r echo=FALSE}
#install.packages("patchwork")
library("readxl")
library("plm")
library("forecast")
library("dplyr")
library("tidyr")
library("ggplot2")
```

```{r}
# Función para convertir el trimestre a fecha
convertir_a_fecha <- function(trimestre) {
  año <- substr(trimestre, 1, 4)
  t <- substr(trimestre, 6, 6)
  
  # Definir el mes de inicio para cada trimestre
  mes_inicio <- ifelse(t == "1", "01", 
                       ifelse(t == "2", "04", 
                              ifelse(t == "3", "07", "10")))
  
  fecha = as.Date(paste(año, mes_inicio, "01", sep = "-"))
  return(format(fecha, "%Y-%m-%d"))
}
```

# Introducción

En España, la situación actual del mercado inmobiliario plantea un desafío considerable para los jóvenes que buscan comprar su primera vivienda. En un contexto de elevadas tasas de paro y dificultades para ahorrar, sumado a la rigidez en las condiciones de financiación hipotecaria, la edad promedio para adquirir una primera vivienda se ha situado en los 31 años. Esta situación refleja no solo las barreras económicas que enfrentan los jóvenes, sino también el impacto de factores como el aumento de los precios de la vivienda y las recientes subidas de los tipos de interés. En nuestro estudio, abordaremos este problema desde el punto de vista del precio de la vivienda, analizando cómo las condiciones macroeconómicas afectan la accesibilidad de la vivienda en España.

A lo largo de este trabajo trataremos de entender el comportamiento del índice del precio de la vivienda, y por consiguiente, el mercado inmobiliario. Durante el escrito trataremos de explicar el mercado de la vivienda a partir de variables macroeconómicas como el IPC, el número de personas activas y el coste salarial. Emplearemos distintos modelos de análisis de datos de panel para poder tener en cuenta la Comunidad Autonoma y el paso del tiempo. Seguidamente seleccionaremos el que más se adecúe a nuestro caso de estudio aplicando distintos métodos de validación.

En segunda instancia, alargaremos el periodo temporal de estudio y nos centraremos en el mercado de la vivienda de la Comunidad Valenciana. Exploraremos el comportamiento de los datos desde 2007 para enfocar nuestro posterior análisis. El principal objetivo de este punto será obtener un modelo que prediga el precio de la vivienda a un trimestre vista (corto plazo) y otro modelo que sirva para predecir a medio largo plazo.

## Preguntas

¿Como se comporta el precio de la vivienda? ¿Como se relaciona el precio de la vivienda con el IPC, las personas activas y el coste salarial? ¿Cual va a ser el precio de la vivienda el trimestre que viene y el siguiente?

# Análisis de datos de panel

## Descripción de los datos

En nuestro archivo datos_trabajo.xlsx, tenemos un total de 204 observaciones y 6 variables. Las variables se definen de la siguiente forma:

-   CCAA: comunidad autónoma (individuos) (no tenemos datos ni de Ceuta ni de Melilla)
-   Periodo: periodo de tiempo, desde 2017 hasta 2020 divididos por trimestres
-   IPC: índices de precio de consumo
-   Personas activas: el número de personas activas
-   Precio vivienda: es un índice confeccionado en España por el Instituto Nacional de Estadística que fue publicado con el propósito de reflejar la evolución de precios de la vivienda.
-   Coste_salarial_total: se refiere al gasto total que una empresa incurre al pagar los salarios y las prestaciones a sus empleados. Se incluyen los sectores de industria, construcción y servicios

Destacar que son datos de panel ya que contienen una serie temporal por cada unidad de unos datos de corte transversal. Al ser datos de panel tenemos individuos (CCAA) y el periodo de tiempo (periodo) y el número de observaciones coincide con el resultado de multiplicar el número de periodos de tiempo por el número de individuos 17x12=204 que son nuestras observaciones.

La pregunta a la que responderemos con estos datos es si influyen y en el caso de que influyan de que forma, el ipc, el coste salarial total y el número de personas activas sobre el precio de la vivienda.

## Carga de datos

Abrimos nuestro fichero de datos y cargamos los datos en un panel data frame. Le especificamos los dos índices que son la comundiad autónoma (CCAA) y el periodo de tiempo (Periodo)

```{r}
datos <- read_excel("./datos_trabajo.xlsx")
data <- pdata.frame(datos, index = c("CCAA","Periodo"), drop.index = FALSE, row.names = TRUE)

# Convertimos a numérico las columnas Personas_activas y Precio_vivienda que estaban en tipo texto y cambiamos el nombre de la columna Coste.salarial.total a Coste_salarial_total.
data$Personas_activas = as.numeric(data$Personas_activas)
data$Precio_vivienda = as.numeric(data$Precio_vivienda)
colnames(data)[colnames(data) == "Coste.salarial.total"] <- "Coste_salarial_total"

head(data)
```

Convertimos a numérico las columnas Personas_activas y Precio_vivienda que estaban en tipo texto y cambiamos el nombre de la columna Coste.salarial.total a Coste_salarial_total.

## Análisis exploratorio

Lo primero que vamos a hacer es ver el comportamiento de los datos que manejamos. A continuación, observamos la evolución de la media para todas las comunidades de nuestras variables a lo largo del tiempo.

```{r}
# Calcular la media de cada variable por periodo
medias_por_periodo <- data %>%
  group_by(Periodo) %>%
  summarise(
    Media_IPC = mean(IPC, na.rm = TRUE),
    Media_Personas_Activas = mean(Personas_activas, na.rm = TRUE),
    Media_Precio_Vivienda = mean(Precio_vivienda, na.rm = TRUE),
    Media_Coste_Salarial_Total = mean(Coste_salarial_total, na.rm = TRUE)
  )

medias_por_periodo$Periodo <- sapply(as.character(medias_por_periodo$Periodo), convertir_a_fecha)
medias_por_periodo$Periodo = as.Date(medias_por_periodo$Periodo)

# Crear los gráficos
p1 <- ggplot(medias_por_periodo, aes(x = Periodo, y = Media_IPC)) +
  geom_line() +
  theme_minimal() +
  ggtitle("Evolución Media del IPC")

p2 <- ggplot(medias_por_periodo, aes(x = Periodo, y = Media_Personas_Activas)) +
  geom_line() +
  theme_minimal() +
  ggtitle("Evolución de Personas Activas")

p3 <- ggplot(medias_por_periodo, aes(x = Periodo, y = Media_Precio_Vivienda)) +
  geom_line() +
  theme_minimal() +
  ggtitle("Evolución del Precio de Vivienda")

p4 <- ggplot(medias_por_periodo, aes(x = Periodo, y = Media_Coste_Salarial_Total)) +
  geom_line() +
  theme_minimal() +
  ggtitle("Evolución del Coste Salarial Total")

# Mostrar los gráficos en un grid
library(gridExtra)
grid.arrange(p1, p2, p3, p4, ncol = 2)
```

1.  **Evolución Media del IPC**: El IPC muestra fluctuaciones a lo largo del tiempo, con un leve aumento en la tendencia. Como medida de la inflación, un aumento en el IPC podría influir en el poder adquisitivo y, por tanto, en la capacidad de los consumidores para comprar viviendas.

2.  **Evolución de Personas Activas**: Hay una tendencia general ascendente en el número de personas activas, lo que puede estar relacionado con una economía en crecimiento. Un aumento en la fuerza laboral activa podría correlacionarse con una mayor demanda de vivienda, ya que más personas podrían tener los medios para comprar o alquilar.

3.  **Evolución del Precio de Vivienda**: Esta línea muestra una tendencia claramente ascendente, lo que indica un incremento constante en el precio de la vivienda. Esta variable es el foco principal del análisis y es la única que no presenta un patrón estacional.

4.  **Evolución del Coste Salarial Total**: El coste salarial total también presenta una tendencia al alza, lo cual podría interpretarse como un aumento en los costos para las empresas. Aunque esta variable no se relaciona directamente con el mercado de la vivienda, los salarios más altos podrían aumentar la capacidad de los trabajadores para adquirir viviendas, afectando así la demanda y, posiblemente, los precios.

Cabe destacar que el patrón estacional del coste salarial y de la evolución del PIB es similar, ambos presentan una forma de M cada año, en cambio la evolución de personas activas es más parecido a una U invertida, con su pico en el segundo o tercer trimestre del año.

```{r}
# Calcular la media de cada variable por CCAA
medias_por_CCAA <- data %>%
  group_by(CCAA) %>%
  summarise(
    Media_IPC = mean(IPC, na.rm = TRUE),
    Media_Personas_Activas = mean(Personas_activas, na.rm = TRUE),
    Media_Precio_Vivienda = mean(Precio_vivienda, na.rm = TRUE),
    Media_Coste_Salarial_Total = mean(Coste_salarial_total, na.rm = TRUE)
  )

p1 <- ggplot(medias_por_CCAA, aes(x = CCAA, y = Media_IPC)) +
  geom_bar(stat = 'identity') +
  theme_minimal() +
  ggtitle("Media del IPC por CCAA") +
  theme(axis.text.x = element_blank(), 
        axis.ticks.x = element_blank())


p2 <- ggplot(medias_por_CCAA, aes(x = CCAA, y = Media_Personas_Activas)) +
  geom_bar(stat = 'identity') +
  theme_minimal() +
  ggtitle("Personas Activas por CCAA") +
  theme(axis.text.x = element_blank(), 
        axis.ticks.x = element_blank())

p3 <- ggplot(medias_por_CCAA, aes(x = CCAA, y = Media_Precio_Vivienda)) +
  geom_bar(stat = 'identity') +
  theme_minimal() +
  ggtitle("Precio de Vivienda por CCAA") +
  theme(axis.text.x = element_blank(), 
        axis.ticks.x = element_blank())

p4 <- ggplot(medias_por_CCAA, aes(x = CCAA, y = Media_Coste_Salarial_Total)) +
  geom_bar(stat = 'identity') +
  theme_minimal() +
  ggtitle("Coste Salarial Total por CCAA") +
  theme(axis.text.x = element_blank(), 
        axis.ticks.x = element_blank())

# Mostrar los gráficos en un grid
library(gridExtra)
grid.arrange(p1, p2, p3, p4, ncol = 2)
```

1.  **Evolución Media del IPC**: Las barras parecen tener alturas similares, lo que indicaría que el IPC medio no varía significativamente entre las CCAA. Sin embargo, la uniformidad del IPC no implica necesariamente una uniformidad en los precios de la vivienda, ya que pueden estar afectados por factores locales específicos.

2.  **Evolución de Personas Activas**: Hay una variabilidad considerable en el número medio de personas activas entre las CCAA. Esto podría reflejar diferencias en la demografía, el mercado laboral y la economía de las regiones. Las regiones con más personas activas podrían tener una mayor demanda de vivienda, lo que a su vez podría influir en los precios.

3.  **Evolución del Precio de Vivienda**: Las diferencias en las medias del precio de vivienda entre las CCAA son notables y pueden reflejar la variación en la demanda de vivienda, el ingreso disponible y las preferencias de los consumidores. La evolución del precio de la vivienda es el resultado de múltiples factores, incluyendo la economía local, la oferta y demanda de viviendas, y las políticas de vivienda.

4.  **Evolución del Coste Salarial Total**: Al igual que con las personas activas, hay una variación significativa entre las CCAA en el coste salarial total medio. Esto podría indicar diferencias en las estructuras del mercado laboral y los niveles de ingreso, lo que a su vez podría afectar a la capacidad de los individuos para comprar viviendas.

Vamos a ver en más profundidad nuestra variable explicada, el precio de la vivienda.

```{r fig.width=12, fig.height=8}
# Libraries
library(tidyverse)
library(hrbrthemes)
library(kableExtra)
options(knitr.table.format = "html")
library(babynames)
library(viridis)
library(plotly)

# Reordenar las CCAA basándose en la media del precio de la vivienda
tmp <- data %>%
  mutate(Periodo = as_datetime(sapply(Periodo, convertir_a_fecha))) %>%
  mutate(CCAA = fct_reorder(CCAA, Precio_vivienda, .fun = mean, .desc=TRUE))%>%
    mutate(name2=CCAA)

p = tmp %>%
  ggplot( aes(x=Periodo, y=Precio_vivienda)) +
    geom_line( data=tmp %>% dplyr::select(-CCAA), aes(group=name2), color="grey", size=0.5, alpha=0.5) +
    geom_line( aes(color=CCAA), color="#69b3a2", size=1.2 )+
    scale_color_viridis(discrete = TRUE) +
    theme(
      legend.position="none",
      plot.title = element_text(size=14),
      panel.grid = element_blank()
    ) +
    ggtitle("Evolución del precio de la vivienda por CCAA") +
    facet_wrap(~CCAA)
p
```

En este conjunto de gráficos, realizamos una exploración visual de la dinámica del precio de la vivienda en las Comunidades Autónomas de España entre 2017 y 2019. El gráfico facilita una comparación inmediata entre comunidades al resaltar la trayectoria de una comunidad específica en cada panel, mientras se muestra el contexto proporcionado por las demás comunidades en un plano secundario.

Observamos una tendencia general al alza en los precios de la vivienda a lo largo del periodo estudiado, lo que podría estar en línea con un entorno de recuperación económica, condiciones favorables de financiamiento y posiblemente una demanda creciente impulsada por factores demográficos y de mercado.

Algunos puntos destacables incluyen:

-   **Madrid y Cataluña**: Estas comunidades muestran una marcada tendencia alcista en los precios de la vivienda, superando a la mayoría de las otras regiones. Esto podría reflejar su condición de centros económicos y culturales, con una demanda de vivienda robusta.

-   **Variabilidad entre Comunidades**: Aunque la tendencia general es al alza, la variabilidad en la tasa de crecimiento es notable. Comunidades como Extremadura y Castilla-La Mancha muestran un crecimiento más moderado, lo que podría sugerir diferencias en las presiones del mercado local o en la actividad económica.

Estos gráficos muestran que si que existen diferencias entre comunidades a pesar de que la evolución es más o menos igual para toda españa. A continuación, vamos a tratar de resolver las preguntas formuladas anteriormente.

## Modelos de datos de panel

Como la pregunta que nos planteamos es como influye el ipc, el coste salarial total y el número de personas activas en el precio de la vivienda, los modelos que se trabajarán a continuación tendrá como variable dependiente el precio de la vivienda y como variable independiente el número de personas activas, el ipc y el coste salarial total.

A continuación, vamos a estimar los distintos modelos e interpretar los coeficientes.

-   Modelo de pool de datos
-   Efectos fijos individuales MCVD
-   Efectos aleatorios

Una vez hechos los modelos, elegiremos tanto desde el punto de vista teórico como con los contrastes de homogeneidad y de Hausman que modelo describe mejor el precio de la vivienda.

### Modelo Pool de datos

Un modelo de pool de datos (pooled data model) es una técnica estadística utilizada en econometría que combina datos de corte transversal y series temporales para analizar y estimar efectos que son constantes a través del tiempo pero pueden variar entre unidades transversales.

```{r}
pool_datos <- plm(Precio_vivienda ~ Personas_activas + IPC + Coste_salarial_total, data = data, model = "pooling")

summary(pool_datos)
```

-   El interceptse estima en -169.69, lo que sería el precio de la vivienda cuando las variables predictoras son cero, aunque este escenario es teóricamente no plausible.

-   La variable 'Personas_activas' tiene un impacto negativo insignificante en el precio de la vivienda (p-valor = 0.7162), indicando que no es un predictor estadísticamente significativo.

-   El 'IPC' muestra un efecto positivo significativo (coeficiente = 2.5965, p-valor \< 0.001), sugiriendo que un aumento en el IPC se asocia con un incremento en el precio de la vivienda.

-   El 'Coste_salarial_total' también es un predictor positivo y significativo (coeficiente = 0.017343, p-valor \< 0.001), indicando que los aumentos en el coste salarial están asociados con precios de vivienda más altos.

-   El modelo es estadísticamente significativo en su conjunto (F-statistic = 47.936, p-valor \< 2.22e-16) y explica aproximadamente el 41.83% de la variabilidad del precio de la vivienda (R-cuadrado ajustado = 0.40955).

En resumen, el modelo sugiere que el IPC y el Coste Salarial Total son variables significativas y positivas en la explicación del precio de la vivienda, mientras que la variable "Personas_activas" no parece tener un impacto significativo.

### Efectos fijos individuales MCVD

El modelo de efectos fijos individuales controla la heterogeneidad no observada que es constante en el tiempo pero varía entre individuos. Mientras que el modelo de pool de datos asume que esta heterogeneidad no observada es inexistente o irrelevante. En nuestro caso los individuos serán las comunidades autónomas.

```{r}
efectos_fijos <- plm(Precio_vivienda ~ Personas_activas + IPC + Coste_salarial_total + as.factor(CCAA), data = data, model="pooling")

summary(efectos_fijos)
```

El intercept es -288.2. Esto representa el valor estimado del precio de la vivienda cuando todas las demás variables son cero y cuando la CCAA es la referencia en nuestro caso Andalucía.

El coeficiente asociado a la variable "Personas_activas" es 0.00955. Es estadísticamente significativo (p-value \< 0.001), y positivo. Cada unidad de aumento en las personas activas se asocia con un aumento de 0.00955 en el precio de la vivienda.

El coeficiente asociado al IPC es 4.05. Es estadísticamente significativo (p-value \< 0.001), y positivo. Cada unidad de aumento en el IPC se asocia con un aumento de 4.05 en el precio de la vivienda.

El coeficiente asociado al "Coste_salarial_total" es -0.01665. Es estadísticamente significativo (p-value \< 0.001), y negativo. Cada unidad de aumento en el coste salarial total se asocia con una disminución de 0.01665 en el precio de la vivienda.

Cada CCAA tiene su propio coeficiente asociado, que representa el cambio promedio en el precio de la vivienda en esa CCAA en comparación con la CCAA de referencia (Andalucía).

El valor F es 121.2 con un p-value muy pequeño (\< 2.2e-16). Esto sugiere que al menos una de las variables independientes o efectos fijos es significativa en la explicación de la variabilidad en el precio de la vivienda. El único coeficiente que no es significativo es el de les Illes Balears. Este resultado sugiere que, según el modelo, no hay evidencia suficiente para afirmar que las Islas Baleares tienen un efecto significativo y diferente en el precio de la vivienda en comparación con Andalucía.

El modelo parece tener un buen ajuste y explica una gran proporción de la variabilidad en el precio de la vivienda. Las variables de personas activas, IPC y coste salarial total son significativas en la predicción del precio de la vivienda, y también hay diferencias significativas en los precios de vivienda entre las diferentes CCAA.

### Efectos aleatorios

El modelo de efectos aleatorios asume que las diferencias individuales no observadas entre las individuos son aleatorias y no correlacionadas con las variables independientes del modelo. A diferencia de los modelos de efectos fijos, que estiman parámetros únicos para cada CCAA, el enfoque de efectos aleatorios incorpora la heterogeneidad no observada en el término del error.

```{r}
efectos_aleatorios <- plm(Precio_vivienda ~ Personas_activas + IPC + Coste_salarial_total , data = data, model = "random")
summary(efectos_aleatorios)
```

El intercept es -254.45. Este valor es la estimación del precio de la vivienda cuando todas las demás variables son cero, y representa la media de los interceptos individuales.

El coeficiente asociado a la variable "Personas_activas" es 8.5802e-05. No es estadísticamente significativo a un nivel de confianza del 95% (p-value = 0.8984).

El coeficiente asociado al IPC es 4.0642. Es estadísticamente significativo (p-value \< 0.001), y positivo. Cada unidad de aumento en el IPC se asocia con un aumento de 4.0642 en el precio de la vivienda.

El coeficiente asociado al "Coste_salarial_total" es -0.013654. Es estadísticamente significativo (p-value \< 0.001), y negativo. Cada unidad de aumento en el coste salarial total se asocia con una disminución de 0.013654 en el precio de la vivienda.

El valor de chi-cuadrado es 430.173 con un p-value muy pequeño (\< 2.22e^-16^). Esto sugiere que al menos una de las variables independientes es significativa en la explicación de la variabilidad en el precio de la vivienda.

La proporción de error idiosincrático es del 14%, mientras que la individual del 86%. La proporción del 14.4% para el efecto idiosincrático significa que una parte relativamente pequeña de la variabilidad total en el precio de la vivienda se debe a factores específicos de cada observación que no están explicados por las variables incluidas en tu modelo. Por otro lado, la proporción del 85.6% para el efecto individual significa que la mayoría de la variabilidad total en el precio de la vivienda se debe a diferencias sistemáticas entre las entidades (individuos) que no están capturadas por las variables incluidas en el modelo.

El modelo de efectos aleatorios tiene en cuenta la variabilidad no observada específica a cada entidad (efecto individual) y la variabilidad no observada específica a cada observación (efecto idiosincrático). Los resultados sugieren que una parte significativa de la variabilidad en el precio de la vivienda se debe a efectos individuales, y las variables IPC y Coste Salarial Total son significativas en la predicción del precio de la vivienda. La variable Personas Activas no parece ser significativa en este modelo.

## Elección del modelo

Desde el punto de vista teórico, entre un modelo de pool de datos y un modelo de efectos fijos individuales eligiremos el modelo de efectos fijos individuales porque existen diferencias en el precio de la vivienda en cada CCAA. No es lo mismo el precio de la vivienda en Madrid que en Castilla-La-Mancha o Extremadura.

Y entre un modelo de efectos fijos o aleatorios, elegiremos el modelo de efectos fijos ya que la muestra no es aleatoria.

Desde el punto de vista de los contrastes, aplicamos en primer lugar el contraste de homogeneidad para elegir entre pool de datos o efectos fijos.

H0: no hay diferencias entre los individuos, todas las alfas son iguales H1: Hay diferencias entre individuos, y por tanto es preferible tenerlas en cuenta

```{r}
pFtest(efectos_fijos, pool_datos)
```

Como el p-valor \< 0.05, rechazamos H0 y por tanto existirán diferencias entre los individuos y nos quedaremos con el modelo de efectos fijos.

A continuación, comparamos el modelo de efectos fijos con el modelo de efectos aleatorios con el test de Hausman

H0: No hay diferencias entre los estimadores por EF o EA, beta de efectos fijos = beta de efectos aleatorios H1: Hay diferencias entre estimadores, probablemente porque los EA estén correlacionados con las regresoras, beta de efectos fijos distinto beta de efectos aleatorios

```{r}
phtest(efectos_fijos, efectos_aleatorios)
```

Como el p-valor \< 0.05, rechazamos H0 y por tanto existirán diferencias entre los estimadores y nos quedaremos con el modelo de efectos fijos.

Se puede concluir, que el modelo que mejor explica el precio de la vivienda es el modelo de efectos fijos individuales MCVD.

# Series temporales

En esta segunda parte del estudio, nos enfocamos en el análisis del precio de la vivienda en la Comunidad Valenciana como una serie temporal. Abarcamos desde el 2007 hasta la actualidad (tercer trimestre de 2023) con una granularidad trimestral. Este período es especialmente significativo, ya que incluye tanto el impacto de la crisis financiera global de 2008 como las fluctuaciones económicas subsiguientes, incluyendo la reciente pandemia de COVID-19. Durante el análisis vamos a descubrir la naturaleza de la serie y vamos a tratar de diseñar un modelo econométrico que prediga el índice del precio de la vivienda. Esto nos permitirá adelantarnos al mercado de bienes raices y saber el estado del mismo. En nuestro caso queremos ser capaces de realizar muy buenas predicciones a un cuatrimestre vista y a medio largo plazo.

Debido a que vamos a cambiar ligeramente nuestra fuente de datos volvermos a realizar una análisis descriptivo para entender el comportamietno del mercado. Seguidamente, aplicaremos los análisis de series temporales aprendidos durante el curso y alguno extra para conseguir un modelo de predicción lo más exacto posible. Es posible que acabemos con dos modelos predictivos y que uno prediga bien a corto plazo y otro a medio plazo.

## Carga de datos

Disponemos de los datos empleados en la parte anterior extendidos, en concreto 57 observaciones que corresponden a todos los trimestres desde el año 2007 hasta el tercer trimestre de 2023. Cabe recalcar que no tenemos ningún dato faltante.

```{r}
# abrimos el fichero donde se encuentran nuestros datos
df <- read_excel("./precio_vivienda_trabajo.xlsx")
```

```{r}
# Como los trimestres están ordenados en sentido contrario al necesario para trabajar series temporales, cambiamos el orden
# Ordenar las filas por la columna de fechas (B)
df <- df[order(as.character(df$Periodo)), ]
head(df)
```

## Análisis exploratorio

El primer paso de nuestro análisis es comprender la forma de nuestros datos e identificar grandes factores socio-económicos que puedan haber afectado. Ya que es importante identificar eventos excepcionales que puedan alterar los datos y sesgar nuestro modelo.

```{r}
# Convertir periodo a fecha
df$Periodo <- sapply(df$Periodo, convertir_a_fecha)
df$Periodo = as.Date(df$Periodo)
```

```{r}
library(ggplot2)

# Crear el gráfico
ggplot(df, aes(x = Periodo, y = Precio_vivienda)) +
  geom_line() +  # Línea para mostrar la evolución del precio
  geom_vline(xintercept = as.Date("2008-01-01"), linetype = "dashed", color = "red") +  # Línea vertical en 2012
  annotate("text", x = as.Date("2008-01-01"), y = max(df$Precio_vivienda), label = "Estallido burbuja", hjust = -0.2, vjust = 1, color = "red") +
  labs(title = "Evolución del Precio de la Vivienda en España (2007-2023)",
       x = "Periodo",
       y = "Precio de la Vivienda") +
  geom_vline(xintercept = as.Date("2014-01-01"), linetype = "dashed", color = "blue") +  # Línea vertical en 2012
  annotate("text", x = as.Date("2014-01-01"), y = max(df$Precio_vivienda), label = "Empieza a remontar el precio", hjust = -0.05, vjust = 1, color = "blue") +
  geom_vline(xintercept = as.Date("2020-03-12"), linetype = "dashed", color = "darkgreen") +  # Línea vertical en 2012
  annotate("text", x = as.Date("2020-03-12"), y = max(df$Precio_vivienda), label = "COVID-19", hjust = -0.1, vjust = 1, color = "darkgreen") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") # Formato del eje X
```

La línea continua representa la serie temporal del precio, evidenciando tres momentos críticos en el mercado inmobiliario español, marcados por líneas verticales punteadas y anotaciones explicativas.

Primero, la línea roja punteada señala el año 2008, coincidiendo con el estallido de la burbuja inmobiliaria. Aquí, se observa un pico seguido de un descenso abrupto, reflejando la caída de precios post-crisis financiera. Este fenómeno marcó el comienzo de un periodo recesivo en el que los precios tocaron su punto más bajo el último trimestre de 2013.

Posteriormente, la línea azul punteada 2014 sugieren un punto de inflexión donde se empieza a percibir una recuperación gradual de los precios. Esta tendencia ascendente indica un fortalecimiento del mercado que podría estar vinculado a mejoras en la economía española y un incremento en la demanda de vivienda.

Finalmente, la línea punteada verde oscura resalta el impacto de la pandemia de COVID-19 en marzo de 2020. Contrario a lo esperado, después de un breve periodo de estancamiento, el gráfico muestra un aumento sorprendente en los precios, lo que podría deberse a una combinación de factores como políticas de estímulo, cambios en las preferencias de vivienda post-confinamiento, y una bajada en las tasas de interés.

Este análisis gráfico sirve como una herramienta esencial para comprender la dinámica del mercado inmobiliario español. A partir de lo que vemos visto podríamos dividir la serie temporal en tres trozos separados por el estallido de la burbuja y cuando empieza a remontar el precio. Omitiremos el efecto de la pandemia porque no parece influir de manera notable en la tendencia del precio.

## Modelado de series temporales

Visto el comportamiento de los datos vamos a abordar el análisis desde dos perspectivas. En primera instancia trateremos de crear un modelo que sea capaz de predecir el precio de la vivienda entrenandolo con todos los datos que tenemos a nuestra disposición. Esto podría ayudar a que nuesto modelo sepa adaptarse a cambios de tendencia. Para ello, vamos a emplear un modelo ARIMA y calcularemos los mejores parámetros con la función auto.arima de forecast.

Por otra parte, trataremos de conseguir un modelo de predicción entrenandolo solo con los datos a partir de 2014, este modelo eliminará el sesgo provocado por la burbuja y puede que sea mejor para predicciones a medio plazo. Para este modelo utilizaremos:

-   Regresión lineal

-   Regresión cuadrática

-   Regresión exponencial cuadrática

-   Modelos ARIMA

### Modelo con todos los datos

Dada la forma de los datos podríamos tratar de ajustar el modelo con una función seno o coseno, sin embargo, además de no conocer su implementación, la velocidad de bajada es mayor a la velocidad de subida del precio. En carencia de una función matemática para aproximar optamos por un modelo ARIMA.

```{r}
df_completo = df

df_completo.ts<-ts(df_completo$Precio_vivienda, start=c(1,1), end=c(17,3), freq = 4)

autoplot(df_completo.ts)
```

Vamos a separar nuestros datos en entrenamiento y test para luego hacer la validación. Los datos test llegan hasta el primer trimestre de 2022.

-   Datos test: [T1_2007 - T1_2022]

-   Datos validación: [T2_2022 - T3_2023]

```{r}
completo_train_ends = c(16,1)
completo_valid_starts = c(16,2)
completo_valid_ends = c(17,3)

df_completo.ts.train<-window(df_completo.ts,start=c(1,1),end=completo_train_ends)
df_completo.ts.valid<-window(df_completo.ts,start=completo_valid_starts,end=completo_valid_ends)
```

#### Predicción a medio plazo

```{r}
df_completo.autoarima<-auto.arima(df_completo.ts.train)

df_completo.autoarima
```

El modelo que nos devuelve la función auto.arima es:

1.  **Especificación del Modelo ARIMA**: La serie se ha modelado con un ARIMA(2,2,0)(0,0,1)[4]. Esto significa que el modelo es un ARIMA estacional con:

    -   **AR(2)**: Dos términos autoregresivos en la parte no estacional del modelo, lo que sugiere que el valor actual de la serie está relacionado linealmente con los dos valores anteriores.

    -   **I(2)**: Dos diferencias no estacionales, indicando que es necesario diferenciar dos veces la serie para hacerla estacionaria.

    -   **MA(0)**: Ningún término de medias móviles en la parte no estacional, lo que indica que los errores (shocks o novedades) no se propagan a valores futuros.

    -   **SMA(1)**: Un término de medias móviles en la parte estacional con periodicidad 4, que refleja la influencia del error (shock) de un valor pasado estacionalmente en los valores futuros.

    -   **Periodicidad [4]**: El modelo identifica una estacionalidad en los datos con una periodicidad de 4, lo que es común en datos trimestrales.

2.  **Coeficientes**:

    -   **ar1 (-0.6533)** y **ar2 (-0.2343)**: Son los coeficientes de los términos autoregresivos. Ambos son negativos, lo que indica una relación inversa entre los precios actuales y los anteriores. Los errores estándar asociados (s.e.) son relativamente pequeños, lo que sugiere que los coeficientes son significativamente diferentes de cero.

    -   **sma1 (0.5402)**: Es el coeficiente del término de medias móviles estacionales. Un valor positivo sugiere que hay un efecto directo del error de un valor pasado en el mismo trimestre del año anterior.

3.  **Medidas de Rendimiento**:

    -   **sigma\^2 (2.484)**: Varianza del error del modelo, cuánto varían los residuos alrededor de cero.

    -   **log likelihood (-109.86)**: Una medida de qué tan bien el modelo se ajusta a los datos; cuanto más alto, mejor.

    -   **AIC (227.72)** y **BIC (236.03)**: Criterios de información que equilibran la bondad del ajuste del modelo con su complejidad. El modelo con el valor más bajo es preferible. AICc es una versión corregida del AIC para muestras pequeñas.

4.  **Error del Conjunto de Entrenamiento**:

    -   **ME (Media del Error)**: Casi cero, lo que indica que no hay sesgo en los residuos.

    -   **RMSE (Raíz del Error Cuadrático Medio)** y **MAE (Error Absoluto Medio)**: Medidas de la diferencia entre los valores predichos y los observados. Mientras más bajos, mejor el ajuste del modelo.

    -   **MPE (Error Porcentual Medio)** y **MAPE (Error Porcentual Absoluto Medio)**: Proporcionan una perspectiva del error en términos porcentuales. Un MAPE de 1.02% es bastante bajo, indicando buen ajuste.

    -   **MASE (Error Absoluto Medio Escalado)**: Comparado con un modelo ingenuo, un MASE \< 1 sugiere que el modelo tiene un buen rendimiento predictivo.

    -   **ACF1 (Primera Autocorrelación de los Residuos)**: Cercano a cero, lo que indica que no hay autocorrelación en los residuos y que el modelo está capturando adecuadamente la estructura temporal de los datos.

En resumen, los resultados indican que el modelo ARIMA(2,2,0)(0,0,1)[4] ajustado parece ser adecuado y capaz de capturar la dinámica de la serie temporal del precio de la vivienda. Los errores son bajos, y no parece haber un sesgo sistemático en las predicciones del modelo.

```{r}
autoplot(cbind(df_completo.autoarima$fitted,df_completo.ts), xlab="Año", ylab="Indice precio vivienda")
```

El gráfico presenta la comparación entre los valores reales del índice de precios de la vivienda (en azul) y las predicciones generadas por el modelo ARIMA(2,2,0)(0,0,1)[4] (en rojo) a lo largo del tiempo. Se observa una estrecha alineación entre ambas series, indicando un ajuste adecuado del modelo a los datos históricos.

Las predicciones del modelo capturan las tendencias y los cambios de dirección en el índice de precios, reflejando tanto el pico pre-crisis como el posterior declive y recuperación. Podemos observar como los periodos con mayor error son aquellos en los que se produce un cambio de tendencia, como en el punto en el que empiezan a remontar los precios de la vivienda

```{r}
library("TSPred")

df_completo.autoarima.pred.valid <- forecast(df_completo.autoarima, h = length(df_completo.ts.valid))

plotarimapred(df_completo.ts, df_completo.autoarima.pred.valid, xlim=c(1,18), range.percent = 0.001)
```

La línea de predicción parece iniciar cerca de la continuidad de la serie real, lo que indica un buen ajuste inicial del modelo. Sin embargo, el área de confianza se amplía progresivamente con el tiempo, indicando un aumento en la incertidumbre de las predicciones a medida que nos alejamos del último punto conocido. Esto se debe a que las predicciones de los modelos ARIMA se basan en la suposición de que las condiciones pasadas, reflejadas en la estructura autoregresiva y de medias móviles, se mantendrán en el futuro.

Con cada nuevo paso de predicción, los errores se acumulan y la base de información del modelo para realizar la predicción siguiente se debilita, ya que se basa cada vez más en predicciones en lugar de en observaciones reales. Este fenómeno es conocido como 'decadencia de la predicción'. Además, eventos futuros no anticipados por el modelo, cambios en la tendencia subyacente, o el impacto de choques externos que no se han incorporado en el modelo histórico, pueden contribuir a una disminución en la precisión de las predicciones a largo plazo.

Para analizar lo bueno que es un modelo nos fijaremos en los datos test. A continación analizamos los parámetros de bondad del modelo. Para este trabajo vamos a utilizar un R^2^ un poco distinto, en vez de ser el porcentaje de variabilidad que explica el modelo con respecto a su media, será con respecto a una predicción ingenua. Para calcularlo modificaremos la suma de cuadrados total, en lugar de calcularla con la media lo haremos con la última predicción de los datos test. De esta forma, podremos comparar fácilmente cuanto mejor es nuestro modelo a una predicción ingenua.

```{r}
bondad = function(real, comparacion, aprox) {
  errores = real - aprox

  # Calcula el RMSE
  rmse <- sqrt(mean(errores^2))
  rmse
  
  # Calcula MAE
  mae <- mean(abs(errores))
  
  # Calcula MAPE
  mape <- mean(abs((errores) / real)) * 100


  # Calculate the total sum of squares (SST)
  sst <- sum((real - comparacion)^2)
  
  # Calculate the residual sum of squares (SSE)
  sse <- sum((real - aprox)^2)
  
  # R-squared is 1 - (SSE/SST)
  r_squared <- 1 - (sse/sst)
  r_squared
  cat('\n')
  cat('MAE: ', round(mae, 6), '\n')
  cat('MAPE:', round(mape, 6), '\n')
  cat('RMSE:', round(rmse, 6), '\n')
  cat('R^2*:', round(r_squared, 6), '\n')
  cat('\n')
}

ultima_observacion_train = (completo_train_ends[1] -1) * 4 + completo_train_ends[2]

bondad(df_completo.ts.valid, df_completo.ts[ultima_observacion_train], df_completo.autoarima.pred.valid$mean)
```

1.  **MAE: 7.538861** - Este valor indica que, en promedio, nuestras predicciones se desvían por aproximadamente 7.54 unidades del valor real. Este nivel de error, dependiendo de la escala de los precios de vivienda, puede ser considerado como moderado.

2.  **MAPE: 5.609502%** - El error porcentual absoluto medio muestra que hay un error del 5.61% en nuestras predicciones. Este indicador es útil para comprender el error en términos relativos y ofrece una perspectiva de la precisión del modelo independientemente de la escala de los datos.

3.  **RMSE: 8.428808** - La raíz del error cuadrático medio sugiere que las predicciones suelen estar a unas 8.43 unidades de distancia del valor real. Dado que el RMSE penaliza más los errores grandes, este valor nos indica que hay variabilidad en la precisión de las predicciones.

4.  **R\^2\*: -0.871797** - Con la nueva definición, este R\^2 compara el modelo con una predicción ingenua. Este valor indica que el modelo no está superando una predicción simple basada en la última observación. Esto puede ser una señal de que el modelo necesita mejoras, pero no necesariamente sugiere una inadecuación tan grave como lo haría un R\^2 negativo en el cálculo tradicional.

Por lo tanto, estos resultados sugieren la necesidad de una revisión y posible ajuste del modelo, o la exploración de enfoques alternativos que puedan manejar mejor la incertidumbre y los cambios en las tendencias a largo plazo. Visto que con todos los datos el modelo ARIMA para medio plazo no es recomendable pasamos a la predicción a corto plazo.

#### Predicción a corto plazo

Vamos ha crear un algoritmo que calcule a un trimestre vista y vaya reentrenando el modelo cada vez que le entra un dato nuevo. Esto tiene sentido porque, a pesar de estar asumiendo un coste computacional importante solo tenemos un dato por trimestre, por lo tanto, nos lo podemos permitir. Pero, si que vamos a respetar el tipo de ARIMA sacado anteriormente (2, 2, 0) (0, 0, 1) [4].

```{r}
# Creamos una función que calcula el modelo y hace la prediccón del siguiente trimestre al índicado.
arima_pred1 = function(ts, trimestre) {
  ts.train = window(ts,start=c(1,1),end=trimestre)
  arima = Arima(ts.train, order = c(2, 2, 0), seasonal = list(order = c(0, 0, 1),  period = 4))
  pred = forecast(arima, h = 1)
  return(pred)
}

# Creamos una función genérica que nos devuelva las predicciones y los intervalos de confianza dado un intervalo de validazión
pred1 = function(df, fun, train_starts, valid_ends) {
  pred_h1 <- data.frame(
    "Point Forecast" = numeric(0),
    "Lo 80" = numeric(0),
    "Hi 80" = numeric(0),
    "Lo 95" = numeric(0),
    "Hi 95" = numeric(0)
  )
  ini_year = train_starts[1]
  end_year = valid_ends[1]
  for (y in ini_year:end_year){
    for (t in 1:4){
      if ((!(y == valid_ends[1] && t > valid_ends[2]-1)) &&
           (!(y == train_starts[1] && t < train_starts[2]))){
        p = fun(df, c(y, t))
        pred_h1[nrow(pred_h1)+1,] = as.data.frame(p)
        }
     }
  }
  pred_h1
}
```

```{r}
autoarima.pred_h1 = pred1(df_completo.ts, arima_pred1, completo_train_ends, completo_valid_ends)
autoarima.pred_h1.ts = ts(autoarima.pred_h1$Point.Forecast, start = completo_valid_starts, end = completo_valid_ends, frequency = 4)

autoplot(cbind(df_completo.autoarima$fitted,df_completo.ts, autoarima.pred_h1.ts), xlab="Año", ylab="Indice precio vivienda") +
  scale_color_manual(values = c("#E8943A", "#566B8A", "#E34836"))

bondad(df_completo.ts.valid, mean(df_completo.ts.valid), autoarima.pred_h1.ts) 
```

Al analizar la imagen del rendimiento de nuestro modelo, la línea roja que representa las predicciones de test muestra un ajuste razonable a los datos reales, aunque hay margen para mejorar. Los parámetros de desempeño del modelo son:

-   **MAE: 2.042988**, que indica la diferencia media entre los valores predichos y los reales.

-   **MAPE: 1.522266%**, que refleja el porcentaje medio de error en las predicciones.

-   **RMSE:** **2.23927**, proporcionando una medida de la calidad del modelo en cuanto a la variabilidad de los errores de predicción.

-   **R\^2: 0.333522**, lo cual sugiere que nuestro modelo explica aproximadamente un 33.35% de variabilidad con respecto a un modelo ingenuo.

Estos indicadores de desempeño nos muestran que, aunque las predicciones son generalmente cercanas a los valores reales, debemos trabajar en la mejora del modelo para aumentar la precisión y la capacidad explicativa del mismo.

### Modelo con los datos a partir de 2014

Después de haber analizado modelos que incluyen el rango completo de datos históricos, ahora vamos a enfocarnos en los datos a partir de 2014. Esta fecha marca un hito significativo, ya que corresponde al siguiente trimetre después del punto más bajo en el precio de la vivienda.

Al limitar nuestro análisis a este periodo de tiempo más reciente, esperamos no solo simplificar la complejidad del modelo sino también aumentar la precisión de nuestras predicciones al concentrarnos en un mercado inmobiliario que ha mostrado una dinámica distinta en comparación con el comportamiento previo a 2014. Este enfoque segmentado nos permitirá ajustar mejor nuestros modelos a las tendencias actuales.

Continuamos con nuestro plantemiento de conseguir predicciones a medio y a corto plazo, pudiendo suponer dos modelos distintos.

Dividimos los datos en:

-   Datos test: [T1_2014 - T1_2022]

-   Datos validación: [T2_2022 - T3_2023]

```{r}
# Definimos ciertas variables genéricas de nuestro análisis
train_ends = c(9, 1)
valid_starts = c(9, 2)
valid_ends = c(10, 3)
```

```{r}
df_partido = df %>% filter(year(Periodo) >= 2014)

df_partido.ts<-ts(df_partido$Precio_vivienda, start=c(1,1), end=c(10,3), freq = 4)

autoplot(df_partido.ts)
```

Este gráfico representa los datos con los que vamos a trabajar para obtener los modelos.

```{r}
df_partido.ts.train<-window(df_partido.ts,start = c(1,1), end = train_ends)
df_partido.ts.valid<-window(df_partido.ts,start = valid_starts, end = valid_ends)
```

#### Predicción a medio plazo

En primer lugar ajustaremos una serie de funciones matemáticas que nos permitan modelar y entender la evolución del precio de la vivienda durante el periodo que comienza en 2014. Consideraremos tres tipos de modelos de regresión para capturar la naturaleza de los datos: lineal, cuadrático y exponencial cuadrático. Seguidamente, al igual que hicimos anteriormente entrenaremos un modelo ARIMA para ver si es capaz de mejorar las predicciones de los modelos funcionales.

**Modelo Lineal**: Este será nuestro punto de partida, proporcionando una línea recta que representa la tendencia general de los precios de la vivienda con el tiempo. La simplicidad del modelo lineal lo hace útil para obtener una vista general y puede servir como una herramienta de comparación para modelos más complejos.

```{r}
df_partido.lm<-tslm(df_partido.ts.train~trend)
```

```{r}
autoplot(cbind(df_partido.lm$fitted,df_partido.ts), xlab="Año", ylab="Indice precio vivienda") + labs(
  title = "Regresión lineal",
  subtitle = "Predicción datos test",
)

a = df_partido.lm.pred.valid <- forecast(df_partido.lm, h = length(df_partido.ts.valid))

d = plotarimapred(df_partido.ts, df_partido.lm.pred.valid, xlim=c(1,valid_ends[1]+1), range.percent = 0.001)

b = bondad(df_partido.ts.valid, mean(df_partido.ts.valid), df_partido.lm.pred.valid$mean)
```

Al observar el primer gráfico, notamos que el modelo lineal ajustado, representado por la línea roja, intenta capturar la tendencia central de la serie temporal del índice de precios de la vivienda.

El segundo gráfico proporciona una visualización clara de las predicciones generadas por el modelo de regresión lineal, incluyendo intervalos de confianza para las proyecciones futuras, denotados por la banda sombreada. Este modelo extiende la línea de tendencia más allá del último punto de datos observado, y la banda de confianza se amplía a medida que nos alejamos de los datos conocidos, reflejando el aumento de la incertidumbre en las predicciones a futuro.

Las estadísticas de bondad de ajuste que se presentan no son buenos. Destacamos el R^2^\* negativos que indica que una predicción ingenua sería mejor.

Aunque el modelo de regresión lineal proporciona una visión general y simplificada de la tendencia, no es adecuado para realizar predicciones precisas en nuestro contexto. La predicción ingenua, que se limita a proyectar el último valor conocido, resultaría en una menor variabilidad de los errores comparado con nuestro modelo lineal.

**Modelo Cuadrático**: Ampliando el modelo lineal, el modelo cuadrático introducirá un término de segundo grado, permitiéndonos capturar no solo la tendencia, sino también la aceleración o desaceleración de los precios a lo largo del tiempo. Esto podría reflejar cambios en el mercado que no son evidentes en un ajuste lineal.

```{r}
df_partido.lm2<-tslm(df_partido.ts.train~ I(trend^2) + trend)

# Ajuste de datos entrenamiento
autoplot(cbind(df_partido.lm2$fitted,df_partido.ts), xlab="Año", ylab="Indice precio vivienda") + labs(
  title = "Regresión cuadrática",
  subtitle = "Predicción datos test",
)

# Ajuste datos de test
df_partido.lm2.pred.valid <- forecast(df_partido.lm2, h = length(df_partido.ts.valid))

plotarimapred(df_partido.ts, df_partido.lm2.pred.valid, xlim=c(1,valid_ends[1]+1), range.percent = 0.001)

bondad(df_partido.ts.valid, mean(df_partido.ts.valid), df_partido.lm2.pred.valid$mean)
```

Para el modelo cuadrático, los estadísticos de bondad de ajuste han mejorado con respecto al modelo lineal, lo que sugiere una mayor precisión en la captura de la variabilidad de los precios de la vivienda. Sin embargo, aún se observa un R² ajustado negativo, aunque menos extremo que en el modelo lineal, lo que indica una mejora en la capacidad del modelo para capturar la variabilidad de los datos en comparación con un modelo ingenuo. La búsqueda de un modelo con un R² ajustado positivo y más cercano a 1 sería ideal, ya que indicaría una capacidad predictiva superior a la de un modelo ingenuo y una captura efectiva de la variabilidad de los datos.

**Modelo Exponencial Cuadrático**: el modelo exponencial cuadrático es considerablemente más complejo y nos ayudará a entender comportamientos no lineales en los datos. Esta función puede ser adecuada para modelar crecimientos de tendencia multiplicativa.

```{r}
df_partido.exp<-tslm(df_partido.ts.train~I(trend^2) + trend, lambda = 0)

# Ajuste de datos entrenamiento
autoplot(cbind(df_partido.exp$fitted,df_partido.ts), xlab="Año", ylab="Indice precio vivienda") + labs(
  title = "Regresión exponencial Cuadrática",
  subtitle = "Predicción datos test",
)

# Ajuste datos de test
df_partido.exp.pred.valid <- forecast(df_partido.exp, h = length(df_partido.ts.valid))

plotarimapred(df_partido.ts, df_partido.exp.pred.valid, xlim=c(1,valid_ends[1]+1), range.percent = 0.001)

bondad(df_partido.ts.valid, mean(df_partido.ts.valid), df_partido.exp.pred.valid$mean)
```

Con el modelo exponencial cuadrático, los estadísticos de bondad de ajuste muestran una mejora notable en comparación con los modelos lineal y cuadrático previamente analizados. Aunque el R² ajustado sigue siendo negativo, está considerablemente más cerca de cero, lo que indica una reducción en la brecha de rendimiento con respecto a un modelo ingenuo.

**Modelo ARIMA:** Avanzando en la complejidad de nuestros modelos econométricos, nos proponemos desarrollar un modelo ARIMA, que se adapta específicamente para analizar y prever series temporales. Para determinar la configuración óptima de los parámetros del modelo ARIMA, emplearemos la función auto.arima. Esta herramienta realiza una búsqueda exhaustiva a través de diferentes combinaciones de parámetros

```{r}
df_partido.autoarima<-auto.arima(df_partido.ts.train)

print("ARIMA resultante:")
df_partido.autoarima

# Ajuste de datos entrenamiento
autoplot(cbind(df_partido.autoarima$fitted,df_partido.ts), xlab="Año", ylab="Indice precio vivienda") + labs(
  title = "ARIMA (0,1,0)",
  subtitle = "Predicción datos test",
)

# Ajuste datos de test
df_partido.autoarima.pred.valid <- forecast(df_partido.autoarima, h = length(df_partido.ts.valid))

plotarimapred(df_partido.ts, df_partido.autoarima.pred.valid, xlim=c(1,valid_ends[1]+1), range.percent = 0.001)

bondad(df_partido.ts.valid, mean(df_partido.ts.valid), df_partido.autoarima.pred.valid$mean)
```

El modelo ARIMA(0,1,0) con deriva proporciona una aproximación simplificada pero potente para modelar la serie temporal del índice de precios de la vivienda en la Comunidad Valenciana. La ausencia de términos autoregresivos (AR) y de medias móviles (MA) indica que el modelo se basa puramente en la diferenciación de los datos (I=1) para lograr la estacionariedad y un término de deriva para captar la tendencia. El coeficiente de deriva de 1.0160 sugiere una tendencia constante en el tiempo, y su error estándar de 0.2045 muestra que este coeficiente es estadísticamente significativo. Este modelo proporciona un enfoque sólido y mucho mejor que los otros modelos para la predicción del índice de precios de la vivienda. Cabe resaltar que el R^2^\* del modelo es el único que es superior a 0, por lo tanto, hemos conseguido superar al modelo ingenuo.

Así pues, es obvio que el mejor modelo de esta sección es el ARIMA (0, 1, 0), por lo tanto, nos quedaremos con ese como mejor representante de los modelos a medio plazo con los datos desde 2014.

#### Predicciones a corto plazo

Una vez tenemos los modelos vamos a comprobar como se comportan en la predicción a corto plazo. Para ello utilizaremos el algoritmo planteado en el modelo con todos los datos y comprobaremos las predicciones que nos devuelven los modelos anteriores desechando el lineal, ya que, no captura bien la naturaleza de los datos.

**Modelo cuadrático**

```{r}
cuad_pred1 = function(ts, trimestre) {
  df_partido.ts.train = window(df_partido.ts,start=c(1,1),end=trimestre)
  df_partido.lm2 = tslm(df_partido.ts.train~ I(trend^2) + trend)
  pred = forecast(df_partido.lm2, h = 1)
  pred
}

cuad.pred_h1 = pred1(df_completo.ts, cuad_pred1, train_ends, valid_ends)

cuad.pred_h1.ts = ts(cuad.pred_h1$Point.Forecast, start = valid_starts, end = valid_ends, frequency = 4)


# Ajuste de datos entrenamiento
autoplot(cbind(df_partido.lm2$fitted.values,df_partido.ts, cuad.pred_h1.ts), xlab="Año", ylab="Indice precio vivienda") +
  scale_color_manual(values = c("#E8943A", "#566B8A", "#E34836"))  + labs(
  title = "Modelo cuadrático",
  subtitle = "Predicción a un trimestre vista",
)

bondad(df_partido.ts.valid, mean(df_partido.ts.valid), cuad.pred_h1.ts)
```

Con el modelo cuadrático observamos en la gráfica que las predicciones siguen de cerca la serie temporal del índice de precios de la vivienda. La línea roja representa las predicciones generadas por el modelo y podemos apreciar que se alinea estrechamente con la serie real, indicada por la línea azul. Los estadísticos de bondad del modelo revelan un desempeño notablemente bueno en la predicción a corto plazo.

**Modelo exponencial cuadrático**

```{r}
exp_pred1 = function(ts, trimestre) {
  df_partido.ts.train = window(df_partido.ts,start=c(1,1),end=trimestre)
  df_partido.lm2 = tslm(df_partido.ts.train~I(trend^2) + trend, lambda = 0)
  pred = forecast(df_partido.lm2, h = 1)
  pred
}

exp.pred_h1 = pred1(df_partido.ts, exp_pred1, train_ends, valid_ends)
exp.pred_h1.ts = ts(exp.pred_h1$Point.Forecast, start = valid_starts, end = valid_ends, frequency = 4)


# Ajuste de datos entrenamiento
autoplot(cbind(df_partido.lm2$fitted.values,df_partido.ts, exp.pred_h1.ts), xlab="Año", ylab="Indice precio vivienda") +
  scale_color_manual(values = c("#E8943A", "#566B8A", "#E34836")) + labs(
  title = "Modelo exponencial cuadrático",
  subtitle = "Predicción a un trimestre vista",
)

bondad(df_partido.ts.valid, mean(df_partido.ts.valid), exp.pred_h1.ts)
```

Para el modelo exponencial al igual que pasaba con las predicciones a medio plazo todos los parámetros son mejores que el modelo cuadrático.

**Arima (0,1,0):**

```{r}
arima2_pred1 = function(ts, trimestre) {
  df_partido.ts.train = window(df_partido.ts,start=c(1,1),end=trimestre)
  modelo = Arima(df_partido.ts.train, order = c(0, 1, 0))
  pred = forecast(modelo, h = 1)
  pred
}

exp.pred_h1 = pred1(df_partido.ts, arima2_pred1, train_ends, valid_ends)
exp.pred_h1.ts = ts(exp.pred_h1$Point.Forecast, start = valid_starts, end = valid_ends, frequency = 4)


# Ajuste de datos entrenamiento
autoplot(cbind(df_partido.autoarima$fitted, df_partido.ts, exp.pred_h1.ts), xlab="Año", ylab="Indice precio vivienda") +
  scale_color_manual(values = c("#E8943A", "#566B8A", "#E34836")) + labs(
  title = "Modelo ARIMA (0,1,0)",
  subtitle = "Predicción a un trimestre vista",
)

bondad(df_partido.ts.valid, mean(df_partido.ts.valid), exp.pred_h1.ts)
```

A diferencia de las predicciones a medio plazo, en este caso, el modelo ARIMA se comporta peor que el modelo exponencial. Esta diferencia, además de verse en el valor de los parametros de bondad, se aprecia en las gráficas. El modelo ARIMA se ve más afectado por el sobreajuste de entrenarlo con todos los datos disponibles. En cambio, las predicciones del otro modelo son más constantes ya que siguen una forma clara.

## Elección de modelos

Tras probar diversos modelos y analizar los gráficos resultantes tenemos un representante de cada apartado.

| Tipo de predicción  | Datos de entrenamiento | Modelo                        |
|-------------------|----------------------|-------------------------------|
| Un trimestre vista: | Todos los datos        | ARIMA(2,2,0)(0,0,1)[4]        |
|                     | A partir de 2014       | Modelo exponencial cuadrático |
| Medio plazo:        | Todos los datos        | ARIMA(2,2,0)(0,0,1)[4]        |
|                     | A partir de 2014       | ARIMA(0,1,0)                  |

Primeramente elegimos nuestro modelo de predicción a un trimestre vista.

```{r fig.width=10, fig.height=8}
# ARIMA
cat("Parámetros de bondad del modelo ARIMA (2,2,0)(0,0,1)[4] con todos los datos:")
bondad(df_completo.ts.valid, mean(df_completo.ts.valid), autoarima.pred_h1.ts) 

# Exponencial
cat("Parámetros de bondad del modelo Exponencial Cuadrático con los datos parciales:")
bondad(df_partido.ts.valid, mean(df_partido.ts.valid), exp.pred_h1.ts)

```

El modelo exponencial cuadrático muestra un **MAE** y **MAPE** más bajos, lo que indica que, en promedio, sus predicciones son más cercanas a los valores reales y el error porcentual es menor. Sin embargo, el **RMSE** es ligeramente mayor en comparación con el modelo ARIMA, lo que sugiere que puede haber algunas predicciones que se desvíen más de los valores reales.

En cuanto al **R²**, el modelo ARIMA tiene un valor ligeramente superior, lo que significa que es capaz de explicar una mayor proporción de la variabilidad de los datos en comparación con el modelo exponencial cuadrático.

Al tomar una decisión entre los dos, se debe considerar el contexto específico de la aplicación de estos modelos. Si se valora más la proximidad de las predicciones a los valores reales (menor error medio), el modelo exponencial cuadrático podría ser preferible. Sin embargo, si se busca un modelo que explique una mayor proporción de la variabilidad de los datos y, posiblemente, sea más estable ante variaciones más amplias, el modelo ARIMA podría ser más adecuado.

Dado que la diferencia en el **R²** entre los dos modelos es relativamente pequeña y el modelo exponencial cuadrático presenta mejores **MAE** y **MAPE**, este último parece ser una opción ligeramente mejor para la predicción a un trimestre vista.

Los modelos predictivos a medio plazo presentan los siguientes parámetros de bondad:

```{r}
cat("Parámetros de bondad del modelo ARIMA (2,2,0)(0,0,1)[4] con todos los datos")
bondad(df_completo.ts.valid, df_completo.ts[ultima_observacion_train], df_completo.autoarima.pred.valid$mean)

cat("Parámetros de bondad del modelo ARIMA (0,1,0) con los datos parciales")
bondad(df_partido.ts.valid, mean(df_partido.ts.valid), df_partido.autoarima.pred.valid$mean)
```

La elección de un modelo para predicciones a medio plazo implica considerar la consistencia y la precisión de las predicciones a lo largo de un período más extenso.

Al comparar estos parámetros, el modelo ARIMA (0,1,0) supera claramente al ARIMA (2,2,0)(0,0,1)[4] en todos los aspectos. Presenta un **MAE**, **MAPE** y **RMSE** significativamente más bajos, lo que indica que sus predicciones son, en promedio, mucho más cercanas a los valores reales y presentan una menor variabilidad de los errores. Además, el **R²** positivo del modelo ARIMA (0,1,0) contrasta fuertemente con el valor negativo del ARIMA (2,2,0)(0,0,1)[4], lo que sugiere que el primero tiene una capacidad predictiva mucho más fuerte.

Sin embargo, cabe resaltar que el modelo entrenado con parte de los datos no estaría preparado para un cambio de tendencia alcista a bajista. Por lo tanto, sería imprescindible tener en cuenta noticias y eventos macroeconómicos, políticos y sociales para valorar la fiabilidad de nuestra predicción. Ante un escenario de previsible estancamiento y posterior caida del mercado inmobiliaría nuestro modelo es probable que no se adaptara correctamente. En cuyo caso es posible que el ARIMA entrenado con todos los datos diera mejores aproximaciones.

## Conclusiones

A lo largo de este análisis hemos conocido como afecta el IPC, el número de personas activas y el coste salarial al mercado de vivienda a través de un modelo de datos de panel de efectos fijos. Sabemos que el número de personas activas y el IPC se relacionan de manera positiva con el precio de la vivienda, siendo la segunda la que más fuerte se relaciona. Por otra parte, el coste salarial total se relaciona de manera negativa con nuestra variable. Además hemos confirmado que existen efectos asociados a cada comunidad que afectan directamente al precio de la vivenda. Por ejemplo, conocemos que la Comunidad Valenciana tiene de media 13.315 puntos más de índice de precio de vivienda que Andalucía.

Por otra parte, hemos obtenido dos modelos de predicción orientados cada uno a un objetivo. Primeramente, para la predicción a corto plazo hemos utilizado un modelo entrenado con todos los datos ya que es el que mejor resultado nos daba, concretamente es un modelo ARIMA (2,2,0)(0,0,1)[4]. En segundo lugar, como modelo predictivo a medio plazo utilizamos un modelo ARIMA (0,1,0) entrenado solo con los datos a partir de 2014.

Con este trabajo explicamos el mercado de la vivienda y obtenemos dos modelos que nos podrían ser de utilidad para anticiparnos al mercado.
